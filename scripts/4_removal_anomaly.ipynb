{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf0d250-04f8-4c04-9487-8162a815207b",
   "metadata": {},
   "source": [
    "# Remove anomaly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a5a23d-e200-44b4-935e-4731396cc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e4fe-9eb9-4479-beba-ac6ae9a38a7a",
   "metadata": {},
   "source": [
    "Based on the previous measures, I remove those outliers: (1) articles longer than 10000 characters (aiming to exclude overly lengthy articles) (2) compression_ration that is smaller or equal to 0.01 and bigger than 0.08 (narrows the dataset to articles with summaries that are neither too brief nor excessively detailed relative to the original content).\n",
    "\n",
    "After Removal, the correlation coefficient increased to 0.09 (Before removal: The correlation coefficient was 0.05) This indicates a small improvement in the correlation coefficient, suggesting a slightly stronger linear relationship between the lengths of the articles and their summaries after removing outliers.\n",
    "\n",
    "For P value, it decreased to 0.11, which was 0.40 before removal. This indicates that the correlation observed is statistically more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2a8d72-5438-4881-aec2-cb89235363d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.09757063591134632, P value: 0.11725614775306956\n",
      "Data saved to 'articles_with_removal.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the existing data from CSV\n",
    "df = pd.read_csv('articles_with_preprocessed_and_measures.csv')\n",
    "\n",
    "# Remove articles longer than 10000 characters\n",
    "df = df[df['preprocessed_articles'].apply(len) <= 10000]\n",
    "\n",
    "# Remove compression_ration that is smaller or equal to 0.01 and bigger than 0.08\n",
    "df = df[(df['compression_ratio'] >= 0.01) & (df['compression_ratio'] < 0.08)]\n",
    "\n",
    "# Calculate correlation and p-value once for the entire dataset\n",
    "article_lengths = df['preprocessed_articles'].apply(len)\n",
    "highlight_lengths = df['preprocessed_highlights'].apply(len)\n",
    "correlation, p_value = pearsonr(article_lengths, highlight_lengths)\n",
    "\n",
    "# Assign the correlation and p-value to each row in new columns\n",
    "df['correlation'] = correlation\n",
    "df['p_value'] = p_value\n",
    "\n",
    "#df.drop(columns=['highlights', 'article', 'preprocessed_highlights', 'preprocessed_articles'], inplace=True)\n",
    "df.drop('cosine_similarity', axis=1, inplace=True)\n",
    "df.to_csv('articles_with_removal.csv', index=False)\n",
    "\n",
    "print(f\"Correlation: {correlation}, P value: {p_value}\")\n",
    "print(\"Data saved to 'articles_with_removal.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
