{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf765ed-1220-4729-ba02-e7cd950b5864",
   "metadata": {},
   "source": [
    "# Web Scrapping\n",
    "The script iteratively scrapes articles from the culture section of \"Le Figaro\" website, extracting each article's title and content, and then compiles this information into a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b05509-7583-4e4d-b6b8-8dfe1b5badd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb538650-cd3a-4323-afb0-62f5bff58cbf",
   "metadata": {},
   "source": [
    "## Function: get_soup(url) : \n",
    "Parameter: url\n",
    "Fetches the HTML content from a given URL and returns a BeautifulSoup object for parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e3b5bf-fc47-418d-9098-8f351f925e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get soup object from URL\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Will raise HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    return BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d41f9d-c413-4a25-a738-d79957de2f3b",
   "metadata": {},
   "source": [
    "## Function: scrape_article(article_url)\n",
    "Parameter: the URL of the specific article that needs to be scraped.\n",
    "Extracts the title and main content of an article from its URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e18c60-786d-4de7-b6e2-2c5a8d64fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape an individual article\n",
    "def scrape_article(article_url):\n",
    "    soup = get_soup(article_url)\n",
    "    title = soup.find('title').text\n",
    "    article_content = soup.find('div', class_='fig-content-body')\n",
    "    if article_content:\n",
    "        content = ' '.join(article_content.get_text(separator='\\n', strip=True).split())\n",
    "    else:\n",
    "        content = \"Content not found\"\n",
    "    return title, content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05546e69-84b9-468f-ae3f-d080aad9654b",
   "metadata": {},
   "source": [
    "This script also includes a looping structure to navigate through multiple pages of a website and collect data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a63122-b82d-4519-9bc7-3d1c228b313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'articles.csv'\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.lefigaro.fr/culture'\n",
    "\n",
    "data = []  # List to store the data\n",
    "\n",
    "\n",
    "for page_num in range(1, 8):\n",
    "    page_url = f\"{base_url}?page={page_num}\" if page_num > 1 else base_url\n",
    "    soup = get_soup(page_url)\n",
    "    \n",
    "    articles = soup.find_all('article', class_='fig-ranking-profile-container fig-ranking-profile-small-picture')\n",
    "    for article in articles:\n",
    "        a_tag = article.find('a')\n",
    "        if a_tag and 'href' in a_tag.attrs:\n",
    "            article_url = a_tag['href']\n",
    "            if not article_url.startswith('http'):\n",
    "                article_url = 'https://www.lefigaro.fr' + article_url\n",
    "            title, content = scrape_article(article_url)\n",
    "            data.append({'articles': content, 'highlights': title}) \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "\n",
    "df.to_csv('articles.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'articles.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
