{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635ffec3-2510-4dd1-b2c6-35fef36cbdd6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d36aa2de-f248-49da-b35c-f1938fe8bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9b5ea-2a0c-4406-9ebc-c286d0eeab23",
   "metadata": {},
   "source": [
    "## Function: preprocess_text \n",
    "Parameters: text (type: string).\n",
    "This function is designed to preprocess textual data on hightlights(title) and articles by removing punctuation, converting all text to lowercase, and removing stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e6ea8d0-fbe6-4409-a2f6-657512f3358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing data from CSV\n",
    "df = pd.read_csv('articles.csv')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = ''.join([char.lower() for char in text if char.isalnum() or char.isspace()])\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "    return text\n",
    "\n",
    "# Preprocess the text in the 'highlights' and 'article' columns\n",
    "df['preprocessed_highlights'] = df['highlights'].apply(preprocess_text)\n",
    "df['preprocessed_articles'] = df['articles'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe8250-9e8d-4007-b048-a3547707a124",
   "metadata": {},
   "source": [
    "Cosine Similarity: In the context of TF-IDF vectors, it is used to measure how similar the documents are irrespective of their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9133aab-a55e-4310-8090-294c9444fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine preprocessed highlights and articles for vectorization, which ensures the same features space is used for both\n",
    "combined_texts = df['preprocessed_highlights'].tolist() + df['preprocessed_articles'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
    "\n",
    "# Split the TF-IDF representation into two separate matrices for highlights and articles\n",
    "half_n = int(len(tfidf_matrix.toarray()) / 2)\n",
    "tfidf_highlights = tfidf_matrix[:half_n]\n",
    "tfidf_articles = tfidf_matrix[half_n:]\n",
    "\n",
    "# Calculate the cosine similarity for each pair of highlight and article\n",
    "cosine_similarities = [cosine_similarity(tfidf_highlights[i], tfidf_articles[i])[0][0] for i in range(half_n)]\n",
    "\n",
    "# Add the cosine similarity to the DataFrame\n",
    "df['cosine_similarity'] = cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6775d63-82e1-4e29-ad95-440dee3e128c",
   "metadata": {},
   "source": [
    "Compression Ratio: Calculates the ratio of the length of preprocessed highlights to the length of preprocessed articles for each pair. This is typically used to measure how much shorter the highlights are compared to the articles. The mean is 0.03, which indicates indicates a high level of condensation, where the summaries are very brief compared to the original articles.\n",
    "\n",
    "Pearson Correlation Coefficient: Measures the linear correlation between the lengths of the articles and their highlights. A correlation coefficient closer to 1 or -1 implies a stronger linear relationship. The result is 0.05. This implies that as the length of the articles increases, there is a slight tendency for the summaries to be longer, but this tendency is not strong. \n",
    "\n",
    "P-value: Provides the probability of observing the data if the null hypothesis (no association) is true. Small p-values (typically â‰¤ 0.05) suggest strong evidence against the null hypothesis. The result is 0.34158127783660464, which suggests that there is no linear correlation between the lengths of the articles and their summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d3dcd8c-8fee-48bc-b533-cfafef8cad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'articles_with_preprocessed_and_measures.csv'\n"
     ]
    }
   ],
   "source": [
    "# Calculate the compression ratio for each row\n",
    "df['compression_ratio'] = df.apply(lambda row: len(row['preprocessed_highlights']) / len(row['preprocessed_articles']) if len(row['preprocessed_articles']) > 0 else 0, axis=1)\n",
    "\n",
    "# Calculate correlation and p-value once for the entire dataset\n",
    "highlight_lengths = df['preprocessed_highlights'].apply(len)\n",
    "article_lengths = df['preprocessed_articles'].apply(len)\n",
    "correlation, p_value = pearsonr(article_lengths, highlight_lengths)\n",
    "\n",
    "# Assign the correlation and p-value to each row in new columns\n",
    "df['correlation'] = correlation\n",
    "df['p_value'] = p_value\n",
    "\n",
    "# Reorder the DataFrame\n",
    "\n",
    "column_order = ['id', 'articles','highlights','preprocessed_highlights', 'preprocessed_articles','cosine_similarity', 'compression_ratio', 'correlation', 'p_value', ]\n",
    "\n",
    "df = df[column_order]\n",
    "\n",
    "#df.drop(columns=['highlights', 'article'], inplace=True)\n",
    "df.to_csv('articles_with_preprocessed_and_measures.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'articles_with_preprocessed_and_measures.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
